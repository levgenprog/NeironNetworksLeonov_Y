{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HKkhJkUtSdj"
      },
      "source": [
        "__*Attribute Information:*__\n",
        "- Alcohol\n",
        "- Malic acid\n",
        "- Ash\n",
        "- Alcalinity of ash\n",
        "- Magnesium\n",
        "- Total phenols\n",
        "- Flavanoids\n",
        "- Nonflavanoid phenols\n",
        "- Proanthocyanins\n",
        "- Color intensity\n",
        "- Hue\n",
        "- OD280/OD315 of diluted wines\n",
        "- Proline\n",
        "\n",
        "__*class:*__\n",
        "- class_0\n",
        "- class_1\n",
        "- class_2\n",
        "\n",
        "This is a copy of UCI ML Wine recognition datasets. https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
        "\n",
        "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine.\n",
        "\n",
        "__*Original Owners:*__\n",
        "\n",
        "Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.\n",
        "\n",
        "__*Citation:*__\n",
        "\n",
        "Lichman, M. (2013). UCI Machine Learning Repository [https://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
        "\n",
        "__*References*__\n",
        "\n",
        "(1) S. Aeberhard, D. Coomans and O. de Vel, Comparison of Classifiers in High Dimensional Settings, Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland. (Also submitted to Technometrics).\n",
        "\n",
        "The data was used with many others for comparing various classifiers. The classes are separable, though only RDA has achieved 100% correct classification. (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) (All results using the leave-one-out technique)\n",
        "\n",
        "(2) S. Aeberhard, D. Coomans and O. de Vel, “THE CLASSIFICATION PERFORMANCE OF RDA” Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland. (Also submitted to Journal of Chemometrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzHwjqjYtSdp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXuZkQbZtSdr"
      },
      "source": [
        "# Step 0. Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrQSeN4FtSdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c71640-b1a8-4419-c4ab-5af09f187369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "import sklearn.datasets\n",
        "wine = sklearn.datasets.load_wine()\n",
        "wine.data.shape\n",
        "print(wine.data)\n",
        "print(wine.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73wsGRJPtSdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a564f48b-4384-427d-c4f6-cc47bdce62a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13.6400,  3.1000],\n",
            "        [13.6800,  1.8300],\n",
            "        [12.8500,  1.6000],\n",
            "        [13.5100,  1.8000],\n",
            "        [13.6700,  1.2500],\n",
            "        [13.0500,  5.8000],\n",
            "        [13.0500,  2.0500],\n",
            "        [13.4000,  4.6000],\n",
            "        [12.4200,  4.4300],\n",
            "        [12.0800,  1.3300],\n",
            "        [11.8400,  2.8900],\n",
            "        [14.3800,  3.5900],\n",
            "        [11.8200,  1.7200],\n",
            "        [12.8500,  3.2700],\n",
            "        [12.9300,  3.8000],\n",
            "        [12.2200,  1.2900],\n",
            "        [13.5000,  3.1200],\n",
            "        [14.2000,  1.7600],\n",
            "        [12.7700,  2.3900],\n",
            "        [13.8600,  1.5100],\n",
            "        [11.6600,  1.8800],\n",
            "        [12.3700,  1.1700],\n",
            "        [12.3300,  0.9900],\n",
            "        [13.4900,  1.6600],\n",
            "        [12.9300,  2.8100],\n",
            "        [13.8400,  4.1200],\n",
            "        [12.6900,  1.5300],\n",
            "        [13.6200,  4.9500],\n",
            "        [12.9900,  1.6700],\n",
            "        [13.8300,  1.6500],\n",
            "        [13.3900,  1.7700],\n",
            "        [11.7900,  2.1300],\n",
            "        [13.8700,  1.9000],\n",
            "        [13.7600,  1.5300],\n",
            "        [12.0700,  2.1600],\n",
            "        [13.5600,  1.7100],\n",
            "        [12.3400,  2.4500],\n",
            "        [13.6900,  3.2600],\n",
            "        [12.2100,  1.1900],\n",
            "        [13.4900,  3.5900],\n",
            "        [12.2900,  3.1700],\n",
            "        [13.1700,  5.1900],\n",
            "        [14.2200,  3.9900],\n",
            "        [14.2300,  1.7100],\n",
            "        [13.2000,  1.7800],\n",
            "        [13.2700,  4.2800],\n",
            "        [13.2300,  3.3000],\n",
            "        [13.7500,  1.7300],\n",
            "        [12.7000,  3.5500],\n",
            "        [12.7700,  3.4300],\n",
            "        [12.8700,  4.6100],\n",
            "        [12.3700,  1.0700],\n",
            "        [11.9600,  1.0900],\n",
            "        [14.1900,  1.5900],\n",
            "        [13.0300,  0.9000],\n",
            "        [13.5800,  2.5800],\n",
            "        [13.4800,  1.8100],\n",
            "        [13.5200,  3.1700],\n",
            "        [12.3600,  3.8300],\n",
            "        [13.8600,  1.3500],\n",
            "        [12.2000,  3.0300],\n",
            "        [12.0400,  4.3000],\n",
            "        [13.5800,  1.6600],\n",
            "        [12.3700,  1.1300],\n",
            "        [13.2400,  3.9800],\n",
            "        [12.0000,  1.5100],\n",
            "        [11.6200,  1.9900],\n",
            "        [12.5100,  1.7300],\n",
            "        [11.6100,  1.3500],\n",
            "        [14.1000,  2.1600],\n",
            "        [13.9000,  1.6800],\n",
            "        [11.7600,  2.6800],\n",
            "        [12.0000,  0.9200],\n",
            "        [13.3400,  0.9400],\n",
            "        [13.2800,  1.6400],\n",
            "        [13.3200,  3.2400],\n",
            "        [12.3700,  1.2100],\n",
            "        [13.8800,  1.8900],\n",
            "        [12.4300,  1.5300],\n",
            "        [14.3700,  1.9500],\n",
            "        [12.4200,  1.6100],\n",
            "        [11.4500,  2.4000],\n",
            "        [13.0500,  3.8600],\n",
            "        [12.3700,  1.6300],\n",
            "        [12.5300,  5.5100],\n",
            "        [12.4200,  2.5500],\n",
            "        [14.0600,  2.1500],\n",
            "        [12.1600,  1.6100],\n",
            "        [12.0000,  3.4300],\n",
            "        [13.7700,  1.9000],\n",
            "        [11.0300,  1.5100],\n",
            "        [14.0200,  1.6800],\n",
            "        [12.6000,  1.3400],\n",
            "        [12.2900,  1.4100],\n",
            "        [14.0600,  1.6300],\n",
            "        [13.7400,  1.6700],\n",
            "        [13.7300,  1.5000],\n",
            "        [11.6500,  1.6700],\n",
            "        [13.9400,  1.7300],\n",
            "        [12.0800,  2.0800],\n",
            "        [13.2400,  2.5900],\n",
            "        [13.5000,  1.8100],\n",
            "        [12.7900,  2.6700],\n",
            "        [12.0800,  1.3900],\n",
            "        [14.2200,  1.7000],\n",
            "        [12.2500,  3.8800],\n",
            "        [12.3300,  1.1000],\n",
            "        [14.3900,  1.8700],\n",
            "        [14.8300,  1.6400],\n",
            "        [12.7000,  3.8700],\n",
            "        [13.7100,  1.8600],\n",
            "        [12.6000,  2.4600],\n",
            "        [14.1600,  2.5100],\n",
            "        [12.2500,  4.7200],\n",
            "        [12.8200,  3.3700],\n",
            "        [13.0700,  1.5000],\n",
            "        [12.2900,  1.6100],\n",
            "        [11.5600,  2.0500],\n",
            "        [14.7500,  1.7300],\n",
            "        [13.0500,  1.7700],\n",
            "        [12.2500,  1.7300],\n",
            "        [13.7200,  1.4300],\n",
            "        [12.9600,  3.4500],\n",
            "        [11.8700,  4.3100]]) tensor([[12.6700,  0.9800],\n",
            "        [12.8800,  2.9900],\n",
            "        [11.8100,  2.1200],\n",
            "        [12.7200,  1.7500],\n",
            "        [12.8400,  2.9600],\n",
            "        [13.0500,  1.6500],\n",
            "        [12.4700,  1.5200],\n",
            "        [12.0800,  1.8300],\n",
            "        [13.2900,  1.9700],\n",
            "        [14.1000,  2.0200],\n",
            "        [13.7300,  4.3600],\n",
            "        [12.0800,  1.1300],\n",
            "        [13.1100,  1.0100],\n",
            "        [12.8100,  2.3100],\n",
            "        [12.8600,  1.3500],\n",
            "        [14.1200,  1.4800],\n",
            "        [12.3700,  0.9400],\n",
            "        [12.1700,  1.4500],\n",
            "        [13.4000,  3.9100],\n",
            "        [11.6400,  2.0600],\n",
            "        [14.3000,  1.9200],\n",
            "        [13.8200,  1.7500],\n",
            "        [13.0500,  1.7300],\n",
            "        [13.0800,  3.9000],\n",
            "        [12.5100,  1.2400],\n",
            "        [12.6400,  1.3600],\n",
            "        [13.8800,  5.0400],\n",
            "        [13.3600,  2.5600],\n",
            "        [13.7800,  2.7600],\n",
            "        [11.8200,  1.4700],\n",
            "        [13.1100,  1.9000],\n",
            "        [12.7200,  1.8100],\n",
            "        [11.4100,  0.7400],\n",
            "        [14.3400,  1.6800],\n",
            "        [12.4500,  3.0300],\n",
            "        [13.4500,  3.7000],\n",
            "        [14.1300,  4.1000],\n",
            "        [12.2900,  2.8300],\n",
            "        [13.6300,  1.8100],\n",
            "        [13.4800,  1.6700],\n",
            "        [13.1600,  2.3600],\n",
            "        [11.4600,  3.7400],\n",
            "        [13.8300,  1.5700],\n",
            "        [13.3000,  1.7200],\n",
            "        [13.1600,  3.5700],\n",
            "        [12.5800,  1.2900],\n",
            "        [13.4100,  3.8400],\n",
            "        [14.2100,  4.0400],\n",
            "        [13.7100,  5.6500],\n",
            "        [13.1700,  2.5900],\n",
            "        [12.5200,  2.4300],\n",
            "        [13.5600,  1.7300],\n",
            "        [14.3800,  1.8700],\n",
            "        [11.8400,  0.8900]]) tensor([0, 0, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 1, 1, 1,\n",
            "        2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 0, 2, 2, 0,\n",
            "        2, 1, 2, 1, 1, 0, 1, 2, 0, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
            "        1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
            "        0, 1, 0, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 2, 2, 2, 2, 0, 1, 1, 0, 0,\n",
            "        1, 0, 2, 1]) tensor([1, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2,\n",
            "        2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0,\n",
            "        2, 2, 1, 0, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine.data[:, :2],\n",
        "    wine.target,\n",
        "    test_size=0.3,\n",
        "    shuffle=True)\n",
        "\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "print(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2GCslPUtSds"
      },
      "source": [
        "# Step 1. Preparing a neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ydoIXMCtSds"
      },
      "source": [
        "## Step 1.1. Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iOjBgbytSds"
      },
      "outputs": [],
      "source": [
        "class WineNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super(WineNet, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(2, n_hidden_neurons)\n",
        "        self.activ1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
        "        self.activ2 = torch.nn.Sigmoid()\n",
        "        self.fc3 = torch.nn.Linear(n_hidden_neurons, 3)\n",
        "        self.sm = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = self.activ1(x)\n",
        "      x = self.fc2(2)\n",
        "      x = self.activ2(x)\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "    def inference(self, x):\n",
        "      x = self.forward(x)\n",
        "      x = self.sm(x)\n",
        "\n",
        "\n",
        "wine_net = WineNet(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hATsgtStSdt"
      },
      "source": [
        "## Step 1.2. Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRTWCVi_tSdt"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXFK2nNKtSdt"
      },
      "source": [
        "## Step 1.3. Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF7CjRaxtSdt"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(wine_net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPjlZOdqtSdu"
      },
      "source": [
        "# Step 2. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5hoew9_tSdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e53a41-6ae2-4a13-aeb8-fd2b2a84a687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 1, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "np.random.permutation(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "E-3tKUP3tSdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "16008253-c181-4cc4-e949-84ac6430f4fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a93a1af2b12d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwine_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-5e7f61b1bb03>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not int"
          ]
        }
      ],
      "source": [
        "batch_size = 10\n",
        "\n",
        "for epoch in range(5000):\n",
        "    order = np.random.permutation(len(X_train))\n",
        "    for start_index in range(0, len(X_train), batch_size):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      batch_indexes = order[start_index:start_index + batch_size]\n",
        "      x_batch = X_train[batch_indexes]\n",
        "      y_batch = y_train[batch_indexes]\n",
        "\n",
        "      pred = wine_net.forward(x_batch)\n",
        "\n",
        "      loss_value = loss(pred, y_batch)\n",
        "      loss_value.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      test_preds = wine_net.fordard(X_test)\n",
        "      test_preds = test_preds.argmax(dim=1)\n",
        "      print((test_preds == y_test).float().mean())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LjuWa25tSdu"
      },
      "source": [
        "# Step 3. Visualization of dividing surfaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4pihN0rtSdu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 8)\n",
        "\n",
        "n_classes = 3\n",
        "plot_colors = ['g', 'orange', 'black']\n",
        "plot_step = 0.02\n",
        "\n",
        "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
        "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
        "\n",
        "xx, yy =  torch.meshgrid(torch.arange(x_min, x_max, plot_step),\n",
        "                         torch.arange(y_min, y_max, plot_step))\n",
        "\n",
        "preds = wine_net.inference(\n",
        "    torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1)], dim=1))\n",
        "\n",
        "preds_class = preds.data.numpy().argmax(axis=1)\n",
        "preds_class = preds_class.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, preds_class, cmap='Accent')\n",
        "\n",
        "for i, color in zip(range(n_classes), plot_colors):\n",
        "    indexes = np.where(y_train == i)\n",
        "    plt.scatter(X_train[indexes, 0],\n",
        "                X_train[indexes, 1],\n",
        "                c=color,\n",
        "                label=wine.target_names[i],\n",
        "                cmap='Accent')\n",
        "    plt.xlabel(wine.feature_names[0])\n",
        "    plt.ylabel(wine.feature_names[1])\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YajPAvnZtSdu"
      },
      "source": [
        "# Step 4. Homework (60 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juY_7tb6tSdu"
      },
      "source": [
        "Let's practice with WineNet. Modify the architecture so that all 13 features are accepted as input and perform the following experiments:\n",
        "\n",
        "1. Experiment with the number of neurons in the hidden layers. Try putting a very small number. Is there a threshold value for the number of hidden neurons at which learning becomes impossible?\n",
        "\n",
        "2. Try passing different test_size values to the train_test_split function. At what value of test_size does the network predict worse than Base Rate*? And what is the Base Rate of the wine dataset?\n",
        "\n",
        "3. Does the training time per epoch depend on the batch size? Explore this relationship.\n",
        "\n",
        "As a report attach code and graphs that show all the necessary dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRzlX5XctSdv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}